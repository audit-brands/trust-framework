# Additional Resources: AI Governance Review

**Version:** 1.0

---

## ðŸŽ¯ Objective

This document provides a curated list of external resources to support an AI governance review.

---

### Key Frameworks & Standards

*   **NIST (National Institute of Standards and Technology):**
    *   [NIST AI Risk Management Framework (AI RMF 1.0)](https://www.nist.gov/itl/ai-risk-management-framework) (The leading global framework for managing risks related to AI).
*   **ISO/IEC (International Organization for Standardization):**
    *   [ISO/IEC 23894:2023](https://www.iso.org/standard/77304.html) (Information technology â€” Artificial intelligence â€” Guidance on risk management).
    *   [ISO/IEC 42001](https://www.iso.org/standard/81230.html) (The world's first AI management system standard).
*   **The OECD AI Principles:**
    *   [OECD AI Principles](https://oecd.ai/en/ai-principles) (An intergovernmental standard for responsible stewardship of trustworthy AI).

### Open-Source Tools for AI Fairness & Explainability

*   **AIF360:**
    *   [AIF360 GitHub Repository](https://github.com/Trusted-AI/AIF360) (An extensible open-source toolkit that can help you detect and mitigate unwanted bias in your models).
*   **Fairlearn:**
    *   [Fairlearn Website](https://fairlearn.org/) (An open-source Python package to assess and improve the fairness of machine learning models).
*   **SHAP (SHapley Additive exPlanations):**
    *   [SHAP GitHub Repository](https://github.com/slundberg/shap) (A game theoretic approach to explain the output of any machine learning model).

### Further Reading & Practitioner Guides

*   **The Montreal AI Ethics Institute:**
    *   [MAIEI Website](https://montrealethics.ai/) (A great resource for research and articles on the social and ethical impacts of AI).
*   **AlgorithmWatch:**
    *   [AlgorithmWatch Website](https://algorithmwatch.org/en/) (A non-profit research and advocacy organization that works to evaluate and shed light on the societal impact of algorithmic decision-making).
